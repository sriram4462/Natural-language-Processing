import io
import re
import warnings

import numpy as np
import pandas as pd
import matplotlib.pyplot as plt

from scipy.sparse import hstack, csr_matrix
from scipy.stats import pearsonr

from sklearn.model_selection import train_test_split
from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.linear_model import LinearRegression, Ridge
from sklearn.ensemble import RandomForestRegressor
from sklearn.svm import SVR
from sklearn.decomposition import TruncatedSVD
from sklearn.preprocessing import StandardScaler
from sklearn.pipeline import Pipeline
from sklearn.metrics import mean_squared_error

# Comment these two lines out if you are NOT using Google Colab
from google.colab import files

warnings.filterwarnings("ignore")
RANDOM_STATE = 42


# ==============================
# 1. Load TSV data
# ==============================
def load_tsv_from_colab():
    """
    For Google Colab: prompt for file upload and return loaded DataFrame.
    Expects a train .tsv file with columns such as:
      sentence / text / context
      target_word / word / token
      complexity / score / label / gold
    """
    print("Please upload your train .tsv file.")
    uploaded = files.upload()

    # pick a train*.tsv file, else first .tsv
    train_name = None
    for fn in uploaded:
        if fn.lower().endswith(".tsv") and "train" in fn.lower():
            train_name = fn
            break
    if train_name is None:
        for fn in uploaded:
            if fn.lower().endswith(".tsv"):
                train_name = fn
                break

    if train_name is None:
        raise ValueError("No .tsv file uploaded.")

    df_local = pd.read_csv(io.BytesIO(uploaded[train_name]), sep="\t", encoding="utf-8")
    print(f"Loaded {train_name} with shape {df_local.shape}")
    return df_local


# If using Colab:
df = load_tsv_from_colab()

# If using locally (uncomment and set path):
# df = pd.read_csv("train.tsv", sep="\t", encoding="utf-8")


# ==============================
# 2. Detect columns (sentence, target, label)
# ==============================
col_sentence_candidates = ["sentence", "text", "context", "sentence_context"]
col_target_candidates = ["target_word", "target", "token", "word", "target_token"]
col_label_candidates = ["complexity", "label", "score", "gold"]


def pick_column(candidates, columns):
    for c in candidates:
        if c in columns:
            return c
    return None


COL_SENT = pick_column(col_sentence_candidates, df.columns)
COL_TGT = pick_column(col_target_candidates, df.columns)
COL_Y = pick_column(col_label_candidates, df.columns)

print("Detected columns:")
print("  Sentence:", COL_SENT)
print("  Target  :", COL_TGT)
print("  Label   :", COL_Y)

if COL_SENT is None or COL_TGT is None or COL_Y is None:
    raise ValueError("Could not detect required columns. Check TSV header names.")


# ==============================
# 3. Preprocessing & feature frame
# ==============================
def clean_text(s: str) -> str:
    if pd.isna(s):
        return ""
    s = str(s).strip()
    s = re.sub(r"\s+", " ", s)
    return s


def syllable_count(word: str) -> int:
    """Simple heuristic syllable counter."""
    w = re.sub(r"[^a-zA-Z]", "", str(word)).lower()
    if not w:
        return 0
    groups = re.findall(r"[aeiouy]+", w)
    cnt = len(groups)
    if w.endswith("e"):
        cnt = max(1, cnt - 1)
    return max(1, cnt)


# Build a working DataFrame with the columns we need
work = df[[COL_SENT, COL_TGT, COL_Y]].copy()
work[COL_SENT] = work[COL_SENT].astype(str).apply(clean_text)
work[COL_TGT] = work[COL_TGT].astype(str).apply(clean_text)
work[COL_Y] = work[COL_Y].astype(float)

# Combined text: sentence + marker + target word
work["input_text"] = work[COL_SENT] + " [TARGET] " + work[COL_TGT]

# Simple numeric features
work["target_len"] = work[COL_TGT].apply(len)
work["target_syllables"] = work[COL_TGT].apply(syllable_count)

# Drop any rows with missing values
work = work.dropna(subset=[COL_SENT, COL_TGT, COL_Y]).reset_index(drop=True)

print("Rows after cleaning:", len(work))
print(work.head())


# ==============================
# 4. Train/validation split (80/20)
# ==============================
idx_all = np.arange(len(work))
train_idx, val_idx = train_test_split(
    idx_all, test_size=0.2, random_state=RANDOM_STATE
)

X_text_train = work.loc[train_idx, "input_text"]
X_text_val = work.loc[val_idx, "input_text"]
y_train = work.loc[train_idx, COL_Y].values
y_val = work.loc[val_idx, COL_Y].values

print(f"Train size: {len(train_idx)} | Val size: {len(val_idx)}")


# ==============================
# 5. TF-IDF features
# ==============================
tfidf_sent = TfidfVectorizer(
    max_features=8000, ngram_range=(1, 2), stop_words="english"
)
tfidf_tgt = TfidfVectorizer(max_features=800, ngram_range=(1, 2))

# Fit only on training data to avoid leakage
tfidf_sent.fit(X_text_train)
tfidf_tgt.fit(work.loc[train_idx, COL_TGT])

X_train_sent = tfidf_sent.transform(X_text_train)
X_val_sent = tfidf_sent.transform(X_text_val)

X_train_tgt = tfidf_tgt.transform(work.loc[train_idx, COL_TGT])
X_val_tgt = tfidf_tgt.transform(work.loc[val_idx, COL_TGT])

num_train = np.vstack(
    [
        work.loc[train_idx, "target_len"].values,
        work.loc[train_idx, "target_syllables"].values,
    ]
).T
num_val = np.vstack(
    [
        work.loc[val_idx, "target_len"].values,
        work.loc[val_idx, "target_syllables"].values,
    ]
).T

X_train_all = hstack([X_train_sent, X_train_tgt, csr_matrix(num_train)])
X_val_all = hstack([X_val_sent, X_val_tgt, csr_matrix(num_val)])

print("Feature shapes:")
print("  Train:", X_train_all.shape)
print("  Val  :", X_val_all.shape)


# ==============================
# 6. Helper: RMSE and evaluation
# ==============================
def rmse_compat(y_true, y_pred):
    """Compute RMSE; compatible with older sklearn versions."""
    try:
        return mean_squared_error(y_true, y_pred, squared=False)
    except TypeError:
        return np.sqrt(mean_squared_error(y_true, y_pred))


def evaluate_model(model, X_tr, y_tr, X_v, y_v, name="model"):
    """Fit a model and print RMSE + Pearson correlation."""
    model.fit(X_tr, y_tr)
    preds = model.predict(X_v)
    rmse = rmse_compat(y_v, preds)
    corr = pearsonr(y_v, preds)[0]
    print(f"[{name}] RMSE = {rmse:.4f} | Pearson = {corr:.4f}")
    return preds, rmse, corr


# ==============================
# 7. Train four models
# ==============================
# 7.1 Linear Regression (baseline)
lin = LinearRegression()
pred_lin, rmse_lin, r_lin = evaluate_model(
    lin, X_train_all, y_train, X_val_all, y_val, "Linear Regression"
)

# 7.2 Ridge Regression (L2-regularised)
ridge = Ridge(alpha=1.0, random_state=RANDOM_STATE)
pred_rdg, rmse_rdg, r_rdg = evaluate_model(
    ridge, X_train_all, y_train, X_val_all, y_val, "Ridge Regression"
)

# 7.3 Random Forest (on SVD-reduced features for speed)
svd_rf = TruncatedSVD(n_components=200, random_state=RANDOM_STATE)
X_train_red = svd_rf.fit_transform(X_train_all)
X_val_red = svd_rf.transform(X_val_all)

rf = RandomForestRegressor(
    n_estimators=250,
    max_depth=None,
    max_features="sqrt",
    min_samples_split=2,
    n_jobs=-1,
    random_state=RANDOM_STATE,
)
pred_rf, rmse_rf, r_rf = evaluate_model(
    rf, X_train_red, y_train, X_val_red, y_val, "Random Forest (SVD-200)"
)

# 7.4 SVR (RBF) in latent space (SVD + scaling + SVR)
svr_pipe = Pipeline(
    [
        ("svd", TruncatedSVD(n_components=300, random_state=RANDOM_STATE)),
        ("scaler", StandardScaler()),
        ("svr", SVR(kernel="rbf", C=10, gamma="scale")),
    ]
)
pred_svr, rmse_svr, r_svr = evaluate_model(
    svr_pipe, X_train_all, y_train, X_val_all, y_val, "SVR (SVD + RBF)"
)

# ==============================
# 8. Collect results in a table
# ==============================
results = pd.DataFrame(
    [
        {
            "model": "Linear Regression",
            "rmse": rmse_lin,
            "pearson": r_lin,
        },
        {
            "model": "Ridge Regression",
            "rmse": rmse_rdg,
            "pearson": r_rdg,
        },
        {
            "model": "Random Forest",
            "rmse": rmse_rf,
            "pearson": r_rf,
        },
        {
            "model": "SVR (RBF)",
            "rmse": rmse_svr,
            "pearson": r_svr,
        },
    ]
).sort_values("rmse")

print("\n=== Final Results (sorted by RMSE) ===")
print(results.reset_index(drop=True))


# ==============================
# 9. Visualisation – Figure 1: Bar chart (RMSE & Pearson)
# ==============================
models = results["model"].tolist()
rmse_vals = results["rmse"].tolist()
pearson_vals = results["pearson"].tolist()

x = np.arange(len(models))
width = 0.35

fig, ax1 = plt.subplots(figsize=(8, 5))

# RMSE bars
ax1.bar(x - width / 2, rmse_vals, width, label="RMSE")
ax1.set_ylabel("RMSE (Lower = Better)")
ax1.set_xlabel("Model")
ax1.set_title("Model Performance Comparison – Lexical Complexity Prediction")
ax1.set_xticks(x)
ax1.set_xticklabels(models, rotation=15)
ax1.legend(loc="upper left")

# Pearson bars on secondary axis
ax2 = ax1.twinx()
ax2.bar(x + width / 2, pearson_vals, width, label="Pearson Correlation")
ax2.set_ylabel("Pearson Correlation (Higher = Better)")
ax2.legend(loc="upper right")

fig.tight_layout()
plt.show()

# ==============================
# 10. Visualisation – Figure 2: Scatter plot (Ridge predictions)
# ==============================
plt.figure(figsize=(6, 6))
plt.scatter(y_val, pred_rdg, alpha=0.6, edgecolor="k")
plt.plot([0, 1], [0, 1], "r--", label="Perfect Prediction")
plt.xlabel("True Complexity Score")
plt.ylabel("Predicted Complexity Score")
plt.title("Predicted vs. True Lexical Complexity (Ridge Regression)")
plt.legend()
plt.grid(alpha=0.3)
plt.tight_layout()
plt.show()

# ==============================
# 11. Optional – Binned confusion-style matrix for Ridge
# ==============================
# This is not a true confusion matrix (regression problem),
# but a binned version to visualise under- / over-estimation.
bins = np.linspace(0, 1, 6)  # 5 bins: [0–0.2, 0.2–0.4, ...]
true_bins = np.digitize(y_val, bins) - 1
pred_bins = np.digitize(pred_rdg, bins) - 1

num_bins = len(bins) - 1
cm = np.zeros((num_bins, num_bins), dtype=int)
for t, p in zip(true_bins, pred_bins):
    if 0 <= t < num_bins and 0 <= p < num_bins:
        cm[t, p] += 1

fig, ax = plt.subplots(figsize=(6, 5))
im = ax.imshow(cm, cmap="Blues")
ax.set_xticks(range(num_bins))
ax.set_yticks(range(num_bins))
labels = [f"{bins[i]:.1f}-{bins[i+1]:.1f}" for i in range(num_bins)]
ax.set_xticklabels(labels, rotation=45, ha="right")
ax.set_yticklabels(labels)
ax.set_xlabel("Predicted Complexity Range")
ax.set_ylabel("True Complexity Range")
ax.set_title("Binned Confusion Matrix (Ridge, 5 bins)")

for i in range(num_bins):
    for j in range(num_bins):
        ax.text(j, i, cm[i, j], ha="center", va="center", color="black")

fig.colorbar(im)
fig.tight_layout()
plt.show()
